{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "from nltk.grammar import DependencyGrammar\n",
    "from nltk.parse import (  DependencyGraph,   ProjectiveDependencyParser,    NonprojectiveDependencyParser)\n",
    "from nltk.parse.transitionparser import TransitionParser, Configuration, Transition\n",
    "from nltk.parse import ParserI, DependencyGraph, DependencyEvaluator\n",
    "import tempfile\n",
    "import os\n",
    "from numpy import array\n",
    "from scipy import sparse\n",
    "from sklearn.datasets import load_svmlight_file\n",
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from os import remove\n",
    "import tempfile\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from itertools import chain\n",
    "from pprint import pformat\n",
    "import subprocess\n",
    "import warnings\n",
    "from six import string_types\n",
    "\n",
    "from nltk.tree import Tree\n",
    "from nltk.compat import python_2_unicode_compatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DependencyGraph import myDependencyGraph    # the member functions of the dependency graph have been modified to include the 10th column in the nodes of the dependency graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    " # extract_features function of the Configuration class has been modified here to return the features in the 10th column as training features\n",
    "def extractFeatures(self):      \n",
    "    '''    \n",
    "       param morph_status: whether to take the morphological features in the feature set\n",
    "       param misc_statu: whether to take the additional features in the feature set\n",
    "    '''\n",
    "    result = []\n",
    "    # Todo : can come up with more complicated features set for better\n",
    "    # performance.\n",
    "    if len(self.stack) > 0:\n",
    "        # Stack 0\n",
    "        stack_idx0 = self.stack[len(self.stack) - 1]\n",
    "        token = self._tokens[stack_idx0]\n",
    "        if self._check_informative(token['word'], True):\n",
    "            result.append('STK_0_FORM_' + token['word'])\n",
    "        if 'lemma' in token and self._check_informative(token['lemma']):\n",
    "            result.append('STK_0_LEMMA_' + token['lemma'])\n",
    "        if self._check_informative(token['tag']):\n",
    "            result.append('STK_0_POS_' + token['tag'])\n",
    "        if(morph_status):\n",
    "            if 'feats' in token and self._check_informative(token['feats']):\n",
    "                feats = token['feats'].split(\"|\")\n",
    "                for feat in feats:\n",
    "                    result.append('STK_0_FEATS_' + feat)\n",
    "        \n",
    "        if(misc_status):\n",
    "            if 'misc' in token and self._check_informative(token['misc']):\n",
    "                miscs = token['misc'].split(\"|\")\n",
    "                for misc in miscs:\n",
    "                    result.append('STK_0_MISC_' + misc)\n",
    "        # Stack 1\n",
    "        if len(self.stack) > 1:\n",
    "            stack_idx1 = self.stack[len(self.stack) - 2]\n",
    "            token = self._tokens[stack_idx1]\n",
    "            if self._check_informative(token['tag']):\n",
    "                result.append('STK_1_POS_' + token['tag'])\n",
    "\n",
    "        # Left most, right most dependency of stack[0]\n",
    "        left_most = 1000000\n",
    "        right_most = -1\n",
    "        dep_left_most = ''\n",
    "        dep_right_most = ''\n",
    "        for (wi, r, wj) in self.arcs:\n",
    "            if wi == stack_idx0:\n",
    "                if (wj > wi) and (wj > right_most):\n",
    "                    right_most = wj\n",
    "                    dep_right_most = r\n",
    "                if (wj < wi) and (wj < left_most):\n",
    "                    left_most = wj\n",
    "                    dep_left_most = r\n",
    "        if self._check_informative(dep_left_most):\n",
    "            result.append('STK_0_LDEP_' + dep_left_most)\n",
    "        if self._check_informative(dep_right_most):\n",
    "            result.append('STK_0_RDEP_' + dep_right_most)\n",
    "\n",
    "    # Check Buffered 0\n",
    "    if len(self.buffer) > 0:\n",
    "        # Buffer 0\n",
    "        buffer_idx0 = self.buffer[0]\n",
    "        token = self._tokens[buffer_idx0]\n",
    "        if self._check_informative(token['word'], True):\n",
    "            result.append('BUF_0_FORM_' + token['word'])\n",
    "        if 'lemma' in token and self._check_informative(token['lemma']):\n",
    "            result.append('BUF_0_LEMMA_' + token['lemma'])\n",
    "        if self._check_informative(token['tag']):\n",
    "            result.append('BUF_0_POS_' + token['tag'])\n",
    "        if(morph_status):\n",
    "            if 'feats' in token and self._check_informative(token['feats']):\n",
    "                feats = token['feats'].split(\"|\")\n",
    "                for feat in feats:\n",
    "                    result.append('BUF_0_FEATS_' + feat)\n",
    "        if (misc_status):\n",
    "            if 'misc' in token and self._check_informative(token['misc']):\n",
    "                miscs = token['misc'].split(\"|\")\n",
    "                for misc in miscs:\n",
    "                    result.append('BUF_0_MISC_' + misc) \n",
    "        # Buffer 1\n",
    "        if len(self.buffer) > 1:\n",
    "            buffer_idx1 = self.buffer[1]\n",
    "            token = self._tokens[buffer_idx1]\n",
    "            if self._check_informative(token['word'], True):\n",
    "                result.append('BUF_1_FORM_' + token['word'])\n",
    "            if self._check_informative(token['tag']):\n",
    "                result.append('BUF_1_POS_' + token['tag'])\n",
    "        if len(self.buffer) > 2:\n",
    "            buffer_idx2 = self.buffer[2]\n",
    "            token = self._tokens[buffer_idx2]\n",
    "            if self._check_informative(token['tag']):\n",
    "                result.append('BUF_2_POS_' + token['tag'])\n",
    "        if len(self.buffer) > 3:\n",
    "            buffer_idx3 = self.buffer[3]\n",
    "            token = self._tokens[buffer_idx3]\n",
    "            if self._check_informative(token['tag']):\n",
    "                result.append('BUF_3_POS_' + token['tag'])\n",
    "                # Left most, right most dependency of stack[0]\n",
    "        left_most = 1000000\n",
    "        right_most = -1\n",
    "        dep_left_most = ''\n",
    "        dep_right_most = ''\n",
    "        for (wi, r, wj) in self.arcs:\n",
    "            if wi == buffer_idx0:\n",
    "                if (wj > wi) and (wj > right_most):\n",
    "                    right_most = wj\n",
    "                    dep_right_most = r\n",
    "                if (wj < wi) and (wj < left_most):\n",
    "                    left_most = wj\n",
    "                    dep_left_most = r\n",
    "        if self._check_informative(dep_left_most):\n",
    "            result.append('BUF_0_LDEP_' + dep_left_most)\n",
    "        if self._check_informative(dep_right_most):\n",
    "            result.append('BUF_0_RDEP_' + dep_right_most)\n",
    "\n",
    "    return result\n",
    "\n",
    "Configuration.extract_features = extractFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    train_model takes in a parser, a machine learning model and a list of dependency graphs.\n",
    "    And trains the model based on the training examples created\n",
    "    by the parser.\n",
    "'''\n",
    "\n",
    "def train_model(parser,model, depgraphs,modelfile, verbose=True):\n",
    "\n",
    "    try:\n",
    "        input_file = tempfile.NamedTemporaryFile(prefix='transition_parse.train',dir=tempfile.gettempdir(), delete=False)\n",
    "\n",
    "        if parser._algorithm == parser.ARC_STANDARD:\n",
    "            parser._create_training_examples_arc_std(depgraphs, input_file)\n",
    "        else:\n",
    "            parser._create_training_examples_arc_eager(depgraphs, input_file)\n",
    "\n",
    "        input_file.close()\n",
    "        x_train, y_train = load_svmlight_file(input_file.name)\n",
    "        model.fit(x_train, y_train)\n",
    "        model_pickle= open(modelfile, 'wb')\n",
    "        pickle.dump(model,model_pickle)\n",
    "        model_pickle.close()\n",
    "        \n",
    "    finally:\n",
    "        remove(input_file.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the train and test files\n",
    "with open('UD_Hindi/hi-ud-train.conllu', 'r') as f:\n",
    "    graphs = [myDependencyGraph(entry, top_relation_label='root') for entry in f.read().split('\\n\\n') if entry]\n",
    "with open('UD_Hindi/hi-ud-test.conllu', 'r') as f:\n",
    "    graph_test = [myDependencyGraph(entry, top_relation_label='root') for entry in f.read().split('\\n\\n') if entry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the parsers and machine learning models\n",
    "parser_str_list=['arc-standard','arc-eager']\n",
    "model_list=[LogisticRegression(),svm.SVC(kernel='poly',degree=2, coef0=0,gamma=0.2,C=0.5,verbose=True,probability=True),MLPClassifier(solver='lbfgs',hidden_layer_sizes=75, random_state=1, verbose=True)]\n",
    "status_list=[(False,False),(True,False),(True,True)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE EVALUATION FOR ARC-STANDARD PARSING\n",
      "===============================================\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "\n",
      "Morphological Features:  Not Taken . Additional Features in 10th column:  Not Taken\n",
      "Peformance for Arc-Standard parser and Model  LogisticRegression  :\n",
      "(0.800453514739229, 0.6923658352229781)\n",
      "-----------------------------------------\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "\n",
      "Morphological Features:  Taken . Additional Features in 10th column:  Not Taken\n",
      "Peformance for Arc-Standard parser and Model  LogisticRegression  :\n",
      "(0.8034769463340892, 0.6893424036281179)\n",
      "-----------------------------------------\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "\n",
      "Morphological Features:  Taken . Additional Features in 10th column:  Taken\n",
      "Peformance for Arc-Standard parser and Model  LogisticRegression  :\n",
      "(0.873015873015873, 0.7755102040816326)\n",
      "-----------------------------------------\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "[LibSVM]\n",
      "Morphological Features:  Not Taken . Additional Features in 10th column:  Not Taken\n",
      "Peformance for Arc-Standard parser and Model  SVC  :\n",
      "(0.8495842781557067, 0.7664399092970522)\n",
      "-----------------------------------------\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "[LibSVM]\n",
      "Morphological Features:  Taken . Additional Features in 10th column:  Not Taken\n",
      "Peformance for Arc-Standard parser and Model  SVC  :\n",
      "(0.8616780045351474, 0.7694633408919124)\n",
      "-----------------------------------------\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "[LibSVM]\n",
      "Morphological Features:  Taken . Additional Features in 10th column:  Taken\n",
      "Peformance for Arc-Standard parser and Model  SVC  :\n",
      "(0.9145880574452003, 0.8329554043839759)\n",
      "-----------------------------------------\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "\n",
      "Morphological Features:  Not Taken . Additional Features in 10th column:  Not Taken\n",
      "Peformance for Arc-Standard parser and Model  MLPClassifier  :\n",
      "(0.8140589569160998, 0.7052154195011338)\n",
      "-----------------------------------------\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "\n",
      "Morphological Features:  Taken . Additional Features in 10th column:  Not Taken\n",
      "Peformance for Arc-Standard parser and Model  MLPClassifier  :\n",
      "(0.817838246409675, 0.7135298563869993)\n",
      "-----------------------------------------\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "\n",
      "Morphological Features:  Taken . Additional Features in 10th column:  Taken\n",
      "Peformance for Arc-Standard parser and Model  MLPClassifier  :\n",
      "(0.9002267573696145, 0.800453514739229)\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"PERFORMANCE EVALUATION FOR ARC-STANDARD PARSING\")\n",
    "print(\"===============================================\")\n",
    "for model in model_list:\n",
    "    for morph_status,misc_status in status_list:\n",
    "        parser=TransitionParser(parser_str_list[0])\n",
    "        model_file=train_model(parser,model,graphs,'temp.arcstd.model',True)\n",
    "        print('')\n",
    "        result = parser.parse(graph_test,'temp.arcstd.model')\n",
    "        evaluator = DependencyEvaluator(result,graph_test)\n",
    "        print(\"Morphological Features: \",'Taken' if morph_status else 'Not Taken','. Additional Features in 10th column: ','Taken' if misc_status else 'Not Taken')\n",
    "        print('Peformance for Arc-Standard parser and Model ',str(model)[:str(model).index(\"(\")],' :')\n",
    "        print(evaluator.eval())\n",
    "        print('-----------------------------------------')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERFORMANCE EVALUATION FOR ARC-EAGER PARSING\n",
      "===============================================\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "\n",
      "Morphological Features:  Not Taken  .Additional Features in 10th column:  Not Taken\n",
      "Peformance for Arc-Eager parser and Model  LogisticRegression  :\n",
      "(0.8518518518518519, 0.7377173091458806)\n",
      "-----------------------------------------\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "\n",
      "Morphological Features:  Taken  .Additional Features in 10th column:  Not Taken\n",
      "Peformance for Arc-Eager parser and Model  LogisticRegression  :\n",
      "(0.8624338624338624, 0.7520786092214664)\n",
      "-----------------------------------------\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "\n",
      "Morphological Features:  Taken  .Additional Features in 10th column:  Taken\n",
      "Peformance for Arc-Eager parser and Model  LogisticRegression  :\n",
      "(0.8979591836734694, 0.7981859410430839)\n",
      "-----------------------------------------\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "[LibSVM]\n",
      "Morphological Features:  Not Taken  .Additional Features in 10th column:  Not Taken\n",
      "Peformance for Arc-Eager parser and Model  SVC  :\n",
      "(0.871504157218443, 0.7724867724867724)\n",
      "-----------------------------------------\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "[LibSVM]\n",
      "Morphological Features:  Taken  .Additional Features in 10th column:  Not Taken\n",
      "Peformance for Arc-Eager parser and Model  SVC  :\n",
      "(0.8805744520030234, 0.7906273620559335)\n",
      "-----------------------------------------\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "[LibSVM]\n",
      "Morphological Features:  Taken  .Additional Features in 10th column:  Taken\n",
      "Peformance for Arc-Eager parser and Model  SVC  :\n",
      "(0.9115646258503401, 0.8269085411942555)\n",
      "-----------------------------------------\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "\n",
      "Morphological Features:  Not Taken  .Additional Features in 10th column:  Not Taken\n",
      "Peformance for Arc-Eager parser and Model  MLPClassifier  :\n",
      "(0.8473167044595616, 0.7369614512471655)\n",
      "-----------------------------------------\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "\n",
      "Morphological Features:  Taken  .Additional Features in 10th column:  Not Taken\n",
      "Peformance for Arc-Eager parser and Model  MLPClassifier  :\n",
      "(0.8775510204081632, 0.764928193499622)\n",
      "-----------------------------------------\n",
      " Number of training examples : 500\n",
      " Number of valid (projective) examples : 476\n",
      "\n",
      "Morphological Features:  Taken  .Additional Features in 10th column:  Taken\n",
      "Peformance for Arc-Eager parser and Model  MLPClassifier  :\n",
      "(0.9002267573696145, 0.8102796674225246)\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"PERFORMANCE EVALUATION FOR ARC-EAGER PARSING\")\n",
    "print(\"===============================================\")\n",
    "for model in model_list:\n",
    "    for morph_status,misc_status in status_list:\n",
    "        parser=TransitionParser(parser_str_list[1])\n",
    "        model_file=train_model(parser,model,graphs,'temp.arceager.model',True)\n",
    "        print('')\n",
    "        result = parser.parse(graph_test,'temp.arceager.model')\n",
    "        evaluator = DependencyEvaluator(result,graph_test)\n",
    "        print(\"Morphological Features: \",'Taken' if morph_status else 'Not Taken',' .Additional Features in 10th column: ','Taken' if misc_status else 'Not Taken')\n",
    "        print('Peformance for Arc-Eager parser and Model ',str(model)[:str(model).index(\"(\")],' :')\n",
    "        print(evaluator.eval())\n",
    "        print('-----------------------------------------')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
