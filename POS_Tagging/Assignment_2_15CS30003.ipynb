{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import nltk\n",
    "import copy\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "from nltk.corpus import brown\n",
    "from nltk import bigrams, ngrams, trigrams \n",
    "from nltk.probability import FreqDist as FreqDist  \n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "from collections import Counter\n",
    "from string import digits\n",
    "from scipy import stats\n",
    "import operator\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank,brown\n",
    "\n",
    "corpus = brown.tagged_sents(tagset='universal')[:-100] \n",
    "\n",
    "tag_dict={}\n",
    "word_dict={}\n",
    "\n",
    "for sent in corpus:\n",
    "    for elem in sent:\n",
    "        w = elem[0]\n",
    "        tag= elem[1]\n",
    "\n",
    "        if w not in word_dict:\n",
    "            word_dict[w]=0\n",
    "\n",
    "        if tag not in tag_dict:\n",
    "            tag_dict[tag]=0\n",
    "\n",
    "        word_dict[w]+=1\n",
    "        tag_dict[tag]+=1\n",
    "unigram_prob=dict()\n",
    "V=len(word_dict)\n",
    "for word in word_dict.keys():\n",
    "    unigram_prob[word]=word_dict[word]/V\n",
    "test_data= brown.tagged_sents(tagset='universal')[-100:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I: POS Tagging with HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the start, emission and transition probability matrices for the HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "start={}\n",
    "transition={}\n",
    "emission={}\n",
    "context={}\n",
    "for line in corpus:\n",
    "    previous='<s>'\n",
    "    for word,tag in line:\n",
    "        if(previous=='<s>'):                           # First tag of the sentence\n",
    "            if tag not in context:\n",
    "                context[tag]=0\n",
    "            context[tag]+=1\n",
    "            if tag not in start:\n",
    "                start[tag]=0.0\n",
    "            start[tag]+=1\n",
    "            previous=tag\n",
    "        else:                                          # Rest of the word-tag pairs\n",
    "            if tag not in context:\n",
    "                context[tag]=0\n",
    "            context[tag]+=1\n",
    "            if previous not in transition:\n",
    "                transition[previous]={}\n",
    "            if tag not in transition[previous]:\n",
    "                transition[previous][tag]=0\n",
    "            transition[previous][tag]+=1\n",
    "            previous=tag\n",
    "        if tag not in emission:\n",
    "            emission[tag]={}\n",
    "        if word not in emission[tag]:\n",
    "            emission[tag][word]=0\n",
    "        emission[tag][word]+=1\n",
    "    if '</s>' not in transition[previous]:\n",
    "        transition[previous]['</s>']=0\n",
    "    transition[previous]['</s>']+=1\n",
    "emission_raw=copy.deepcopy(emission)\n",
    "for tag in transition:                                 # Normalizing the counts into probability scores\n",
    "    total_count=float(sum(transition[tag].values())) \n",
    "    for next_tag in transition[tag]:\n",
    "        transition[tag][next_tag]/=(total_count)\n",
    "for tag in start:                                      # Normalizing the counts into probability scores\n",
    "    start[tag]/=float(len(corpus))\n",
    "\n",
    "for tag in emission:                                   # Normalizing the counts into probability scores\n",
    "    total_count=float(sum(emission[tag].values())) \n",
    "    for word in emission[tag]:\n",
    "        emission[tag][word]/=(total_count)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Taggging with HMM Model and Additive Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothed_emission(tag, word,delta):                          # Emission probabilities with additive smoothing\n",
    "    count_pair=emission_raw[tag].get(word,0)\n",
    "    prob=(count_pair+delta)/(context[tag]+delta*V)\n",
    "    return prob\n",
    "\n",
    "def log(x):\n",
    "    if (x==0 ):\n",
    "        return -np.inf\n",
    "    else:\n",
    "        return np.log(x)\n",
    "    \n",
    "def pos_tagger(sentence,delta):\n",
    "    viterbi_scores=dict()\n",
    "    backpointer=dict()\n",
    "    N=len(context.keys())                                         # Number of states except accept state '</s>'\n",
    "    T=len(sentence)\n",
    "    words=['dummy']\n",
    "    words.extend(sentence)\n",
    "    for s in context.keys():                                      # Initialization Step\n",
    "        viterbi_scores[s,1]=log((start.get(s,0))*smoothed_emission(s,words[1],delta))\n",
    "        backpointer[s,1]=0\n",
    "    for t in range(2,T+1):                                        # Recursion Step\n",
    "        for s in context.keys():\n",
    "            max_prob=-np.inf\n",
    "            for s1 in context.keys():\n",
    "                prob=viterbi_scores[s1,t-1]\n",
    "                prob+=log(transition[s1].get(s,0))\n",
    "                prob+=log(smoothed_emission(s,words[t],delta))\n",
    "                if(prob>=max_prob):\n",
    "                    viterbi_scores[s,t]=prob\n",
    "                    backpointer[s,t]=s1\n",
    "                    max_prob=prob\n",
    "    max_prob=-np.inf\n",
    "    for s in context.keys():                                      # Termination Step                                 \n",
    "        prob=(viterbi_scores[s,T])+log(transition[s].get('</s>',0))\n",
    "        if prob>=max_prob:\n",
    "            max_prob=prob\n",
    "            viterbi_scores['</s>',T+1]=prob\n",
    "            backpointer['</s>',T+1]=s      \n",
    "    tag_sequence=list()\n",
    "    tag='</s>'\n",
    "    tag_sequence.append(tag)\n",
    "    for t in range(T+1,0,-1):                                     # Trace the backpointers to get the tag sequence\n",
    "        tag=backpointer[tag,t]\n",
    "        tag_sequence.append(tag)\n",
    "    tag_sequence.reverse()\n",
    "    tag_sequence=tag_sequence[1:len(tag_sequence)-1]\n",
    "    return tag_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['DET', 'NOUN', 'ADJ', 'VERB', 'ADP', '.', 'ADV', 'CONJ', 'PRT', 'PRON', 'NUM', 'X'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring accuracy on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_accuracy(predicted_tags, test_tags):\n",
    "    num_sentences=len(predicted_tags)\n",
    "    scores=list()\n",
    "    total_count=0\n",
    "    num_tags=0\n",
    "    for i in range(num_sentences):\n",
    "        count=0\n",
    "        predicted=predicted_tags[i]\n",
    "        test=test_tags[i]\n",
    "        len_sentence=len(test)\n",
    "        for j in range(len_sentence):\n",
    "            if(predicted[j]==test[j]):\n",
    "                count+=1\n",
    "                total_count+=1\n",
    "            #else:\n",
    "                #print(predicted[j],test[j])\n",
    "        #if(count/len_sentence<0.7):\n",
    "            #print(test_sentences[i])\n",
    "            #print(predicted)\n",
    "            #print(test)\n",
    "            #print(\"\\n\")\n",
    "        scores.append(count/len_sentence)\n",
    "        num_tags+=len_sentence\n",
    "    print(total_count/num_tags)\n",
    "    return np.mean(np.asarray(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences=[[word[0] for word in sentence] for sentence in test_data]\n",
    "test_tags=[[word[1] for word in sentence] for sentence in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_tags=[pos_tagger(sentence,0.001) for sentence in test_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9227215455690886\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9103542356640717"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_accuracy(predicted_tags,test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lis=['S.', 'J.', 'Perelman']\n",
    "pos_tagger(lis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: POS Tagging with CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sents= corpus\n",
    "\n",
    "def baselineFeatures(sent,i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    # Common features for all words\n",
    "    features = {\n",
    "        'bias':1.0,\n",
    "        #'word.lower': word.lower(),\n",
    "        'postag=': postag\n",
    "    }\n",
    "    return features\n",
    "def word2features(sent,i):\n",
    "    #word = sent[i][0]\n",
    "    \n",
    "    #features ={\n",
    "    #'bias': 1.0,\n",
    "    #}\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    # Common features for all words\n",
    "    features = {\n",
    "        'bias':1.0,\n",
    "        'word.lower': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]=' : word[-2:],\n",
    "        'word.isupper': word.isupper(),\n",
    "        'word.istitle': word.istitle(),\n",
    "        'word.isdigit': word.isdigit(),\n",
    "        'postag=': postag\n",
    "    }\n",
    "\n",
    "    # Features for words that are not\n",
    "    # at the beginning of a sentument\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower=' : word1.lower(),\n",
    "            '-1:word.istitle' : word1.istitle(),\n",
    "            '-1:word.isupper' : word1.isupper(),\n",
    "            '-1:word.isdigit' : word1.isdigit(),\n",
    "            '-1:postag': postag1\n",
    "        })\n",
    "    else:\n",
    "        # Indicate that it is the 'beginning of a sentence'\n",
    "        features.update({'BOS':True})\n",
    "\n",
    "    # Features for words that are not\n",
    "    # at the end of a sentument\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower': word1.lower(),\n",
    "            '+1:word.istitle' :word1.istitle(),\n",
    "            '+1:word.isupper' : word1.isupper(),\n",
    "            '+1:word.isdigit' : word1.isdigit(),\n",
    "            '+1:postag':postag1\n",
    "        })\n",
    "    else:\n",
    "        # Indicate that it is the 'end of a sentument'\n",
    "        features.update({'EOS':True})\n",
    "\n",
    "    return features\n",
    "def sent2features(sent):\n",
    "    return [baselineFeatures(sent,i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for _,label in sent]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bias': 1.0, 'postag=': 'DET'},\n",
       " {'bias': 1.0, 'postag=': 'NOUN'},\n",
       " {'bias': 1.0, 'postag=': 'NOUN'},\n",
       " {'bias': 1.0, 'postag=': 'ADJ'},\n",
       " {'bias': 1.0, 'postag=': 'NOUN'},\n",
       " {'bias': 1.0, 'postag=': 'VERB'},\n",
       " {'bias': 1.0, 'postag=': 'NOUN'},\n",
       " {'bias': 1.0, 'postag=': 'DET'},\n",
       " {'bias': 1.0, 'postag=': 'NOUN'},\n",
       " {'bias': 1.0, 'postag=': 'ADP'},\n",
       " {'bias': 1.0, 'postag=': 'NOUN'},\n",
       " {'bias': 1.0, 'postag=': 'ADJ'},\n",
       " {'bias': 1.0, 'postag=': 'NOUN'},\n",
       " {'bias': 1.0, 'postag=': 'NOUN'},\n",
       " {'bias': 1.0, 'postag=': 'VERB'},\n",
       " {'bias': 1.0, 'postag=': '.'},\n",
       " {'bias': 1.0, 'postag=': 'DET'},\n",
       " {'bias': 1.0, 'postag=': 'NOUN'},\n",
       " {'bias': 1.0, 'postag=': '.'},\n",
       " {'bias': 1.0, 'postag=': 'ADP'},\n",
       " {'bias': 1.0, 'postag=': 'DET'},\n",
       " {'bias': 1.0, 'postag=': 'NOUN'},\n",
       " {'bias': 1.0, 'postag=': 'VERB'},\n",
       " {'bias': 1.0, 'postag=': 'NOUN'},\n",
       " {'bias': 1.0, 'postag=': '.'}]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent2features(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[sent2features(s) for s in train_sents]\n",
    "y_train=[sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test=[sent2features(s) for s in test_data]\n",
    "y_test=[sent2labels(s) for s in test_data]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs', \n",
    "    c1=0.1, \n",
    "    c2=0.1, \n",
    "    max_iterations=100, \n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)\n",
    "labels=list(crf.classes_)\n",
    "\n",
    "metrics.flat_f1_score(y_test, y_pred, \n",
    "                      average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_labels = sorted(\n",
    "    labels, \n",
    "    key=lambda name: (name[1:], name[0])\n",
    ")\n",
    "print(metrics.flat_classification_report(\n",
    "    y_test, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57240"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'j'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word='ej'\n",
    "word[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
